name: "resnet_onnx"
platform: "onnxruntime_onnx"
max_batch_size: 16

input [
  {
    name: "input"
    data_type: TYPE_FP32
    dims: [ 3, 32, 32 ]
  }
]
output [
  {
    name: "output"
    data_type: TYPE_FP32
    dims: [ 10 ]
  }
]

# Dynamic Batching 활성화
# Triton이 알아서 요청을 모아서 보냄 (Locust가 보낸 배치를 또 묶을 수도 있음)
dynamic_batching {
  preferred_batch_size: [ 4, 8, 16 ]
  max_queue_delay_microseconds: 100
}

# GPU 인스턴스 설정
instance_group [
  {
    count: 1
    kind: KIND_GPU
  }
]